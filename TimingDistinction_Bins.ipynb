{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02987b-f458-49b9-b193-f175725cfe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1440a0d4-da65-4719-b7f4-f05d0eb5fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42); tf.random.set_seed(42); random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe67184-2818-475a-bd1b-ad67076c6152",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "## Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66ad7f-e231-4714-b2a7-6657cfab28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMAGE GENERATOR \n",
    "def make_square(h=28, w=28, size=8):\n",
    "    img = np.zeros((h,w), dtype=np.float32)\n",
    "    y0 = h//2 - size//2; x0 = w//2 - size//2\n",
    "    img[y0:y0+size, x0:x0+size] = 1.0\n",
    "    return img\n",
    "    \n",
    "def make_circle(h=28, w=28, r=6):\n",
    "    yy, xx = np.mgrid[:h, :w]\n",
    "    cy, cx = h//2, w//2\n",
    "    return ((yy-cy)**2 + (xx-cx)**2 <= r*r).astype(np.float32)\n",
    "\n",
    "IMG_C = make_circle()\n",
    "IMG_S = make_square()\n",
    "IMG__ = np.zeros_like(IMG_C, dtype=np.float32)  # blank / PAD\n",
    "\n",
    "#Show Circle\n",
    "plt.imshow(IMG_C, cmap=\"gray\")  \n",
    "plt.axis(\"off\")               \n",
    "plt.show()\n",
    "\n",
    "#Show Square\n",
    "plt.imshow(IMG_S, cmap=\"gray\")  \n",
    "plt.axis(\"off\")               \n",
    "plt.show()\n",
    "\n",
    "#Show Blank \n",
    "plt.imshow(IMG__, cmap=\"gray\")  \n",
    "plt.axis(\"off\")               \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abddfb37-1145-4ce7-a3d9-3e0c0ac7d725",
   "metadata": {},
   "source": [
    "## Inputs Functons (timing/padding) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a8652-b8de-467a-bb09-744e46f55368",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Inputs functions \n",
    "def expand_events(events, dt_min=0.05, dt_max=0.2, rng=None): #frame simulate 5-20 Hz \n",
    "    \"\"\"\n",
    "    Expand my sequence of events into per-frame images and per-frame durations.\n",
    "\n",
    "    Args:\n",
    "        events (list[tuple[np.ndarray, float]]): Sequence of (image, duration_seconds) pairs. Durations are in seconds (float).\n",
    "        dt_min (float): Minimum per-frame time step in seconds. Default = 0.05 sec\n",
    "        dt_max (float): Maximum per-frame time step in seconds. Default = 0.2 sec\n",
    "        rng (np.random.Generator): Numpy generator used to sample dt in [dt_min, dt_max].\n",
    "\n",
    "    Returns:\n",
    "        frames (np.ndarray):\n",
    "            Image sequence tensor of shape (T, H, W, C). number of frames * frame height * frame width * channels \n",
    "            If input images are (H, W), a channel axis is added so C = 1.\n",
    "        dts (np.ndarray):\n",
    "            Per-frame durations (seconds) tensor, shape (T, 1), such that for each event,\n",
    "            the sum of its chunk of dts equals the event duration up to floating error.\n",
    "\n",
    "    Notes:\n",
    "        - T (the number of frames) depends on total duration and the sampled dt’s:\n",
    "            approx T ≈ total_duration / mean(dt).\n",
    "        - Effective frame rate is between 1/dt_max and 1/dt_min Hz.\n",
    "        - The final dt of each event is clipped so cumulative time matches the\n",
    "          event duration exactly.\n",
    "    \"\"\"\n",
    "    \n",
    "    if rng is None:\n",
    "        raise ValueError(\"expand_events requires an rng passed from make_dataset_with_gaps\")\n",
    "        \n",
    "    frames, dts = [], [] # shape (T, 28, 28, 1); images at each timesteps where T is the sequence length (total number of timesteps(frames))\n",
    "                            # shape (T, 1); duration of each frames\n",
    "    for img, dur in events: #for each (images, durations) ex: (IMG_C, 2.0)\n",
    "        t_remain = dur\n",
    "        while t_remain > 1e-6:  \n",
    "            dt = rng.uniform(dt_min, dt_max) # making frame count not equal to duration, thus the model must integrate elapsed time, i.e., sum of dt = real duration.\n",
    "                                                    #If we change sample rate, the model can still understand time; more like neurons work. \n",
    "            if dt > t_remain:  #make last step fits remaining duration \n",
    "                dt = t_remain\n",
    "           \n",
    "            frames.append(img[..., None])   # save 1 frame of my 2D image (28x28) + 1 dimension at the end to fit ML frameworks (28,28,1)\n",
    "            dts.append([dt])                # save the duration of the frame, shape (T,1) [ [], [], ... ] to know the exact elapsed time, since number of frames doesn't equal duration \n",
    "            t_remain -= dt\n",
    "    return np.stack(frames,0), np.array(dts, np.float32) #Proper time-series tensor on the 0 axis: time x height x width x channels (T, 28, 28, 1)\n",
    "                                                          #and turn the list into an array so it can fed into a neural net \n",
    "                                                           #for exemple, a sequence of 500 frames with our square and cirle 28x28 is (500, 28, 28, 1) with channel 1 and its corresponding dts. \n",
    "\n",
    "\n",
    "\n",
    "def pad_sequence(frames, dts, T_max=1000): \n",
    "    \"\"\"\n",
    "    After using expand_events(), allows my sequences to be all of the same lenght by padding to length T_max so it can be batched for training.\n",
    "\n",
    "    Args:\n",
    "        frames (np.ndarray): sequence of images frames (seconds) intersected by gaps (seconds).\n",
    "        dts (np.ndarray):\n",
    "        T_max (int): Max length of the sequence. Default = 1000 frames/timesteps\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): my frames tensor.\n",
    "        D (np.ndarray): my dts tensor.\n",
    "        \n",
    "    \"\"\"\n",
    "    T = frames.shape[0]\n",
    "    X = np.zeros((T_max,28,28,1), np.float32) #Create a zeros array, hardcoded for my 28x28 pictures. \n",
    "    D = np.zeros((T_max,1), np.float32)\n",
    "    X[:T] = frames  #Fill X with my frames and the rest is from T to T_max \n",
    "    D[:T] = dts     \n",
    "    return X,D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506c5baf-be24-4af5-acb9-5f11127c9430",
   "metadata": {},
   "source": [
    "## Bins Dataset Functions (labels/outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8fc47-dc09-4c48-a490-25730f94b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATESET BINS \n",
    "\n",
    "#Create my bins intervals \n",
    "EDGES_A = np.array([1.0, 2.0, 3.0, 4.0, 5.0])            # 4 bins: [1,2), [2,3), [3,4), [4,5)\n",
    "EDGES_B = np.array([1.0, 2.0, 3.0])                      # 2 bins: [1,2), [2,3)\n",
    "EDGES_C = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0])  # 6 bins: [1,2),...[6,7)\n",
    "\n",
    "#Get the lenght of my bins interval \n",
    "NA = len(EDGES_A) - 1  # 4\n",
    "NB = len(EDGES_B) - 1  # 2\n",
    "NC = len(EDGES_C) - 1  # 6\n",
    "N_CLASSES = NA * NB * NC  # 48 classifications possible in total \n",
    "\n",
    "def bin_index(gap_length, edges):\n",
    "    \"\"\"\n",
    "    This function allows me to find in which bin my specific gap(seconds) is ending in. \n",
    "\n",
    "    Args:\n",
    "        gap_length (float): Lenght of my gap in seconds. \n",
    "        edges (array): Array containing my bins \n",
    "\n",
    "    Returns:\n",
    "        index (int): return the position(index) of my gap inside the specified edge's bins \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    index = np.searchsorted(edges, gap_length, side=\"right\") - 1  #gives the position to the right of the searched item gap_length inside my array. -1 to get the exact bin. \n",
    "                                                                    #if I get 2.3 as my random gap length; my i = 1 because [1.0, 2.0), [2.0, 3.0) thus position [1]. \n",
    "    return int(np.clip(index, 0, len(edges) - 2)) #return my position i and make sure it falls inside a valid range. \n",
    "\n",
    "\n",
    "def label_from_gap(gap_a, gap_b, gap_c):\n",
    "    \"\"\"\n",
    "    Following bin_index(), this function allows me to label my sequence out of the 48 possibility depending on which bins my gaps fall into. \n",
    "\n",
    "    Args:\n",
    "        gap_a (float): my gap_a in seconds.\n",
    "        gap_b (float): my gap_b in seconds.\n",
    "        gap_c (float): my gap_c in seconds.\n",
    "\n",
    "    Returns:\n",
    "        label (int): return a unique label from 0 to 47. Ex: (gap_a_bin_index, gap_b_bin_index, gap_a_bin_index) = (2, 1, 4) -> 2*(NB*NC) + 1*NC + 4 = 2*(2*6) + 1*6 + 4 = 34 \n",
    "                      Explanation : we multiply the gap_bin_index given the total number of combos (mixed-radix (row-major) indexing);\n",
    "                      gap_a_bin_index times NB*NC given us all probabilities with a,\n",
    "                      thus then we do the same with remaining gap_b index * NC and no * NA cause we already did them in the first calculation\n",
    "                      and finally since we did the probabilities of gap_a and gap_b we just do add gap_c to the toal. \n",
    "                      This gives us a unique index between 0 and 47.\n",
    "        \n",
    "    \"\"\"\n",
    "    ia = bin_index(gap_a, EDGES_A)  # from 0 to 3 so again if my gap_a is 2.7 I get ia = 1  \n",
    "    ib = bin_index(gap_b, EDGES_B)  # from 0 to 1\n",
    "    ic = bin_index(gap_c, EDGES_C)  # from 0 to 5 \n",
    "    return ia * (NB * NC) + ib * NC + ic\n",
    "\n",
    "\n",
    "def indices_from_label(label):\n",
    "    \"\"\"\n",
    "    Inverse of label_from_gap to get each gaps indexes.  \n",
    "\n",
    "    Args:\n",
    "        label (int): unique index between 0 and 47.\n",
    "\n",
    "    Returns:\n",
    "        ia (int): index of the gap_a\n",
    "        ib (int): index of the gap_b\n",
    "        ic (int): imdex of the gap_c\n",
    "        \n",
    "    \"\"\"\n",
    "    ia = label // (NB * NC)\n",
    "    ib = (label // NC) % NB\n",
    "    ic = label % NC\n",
    "    return ia, ib, ic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd3019-335e-4f75-89e0-384707ca2f30",
   "metadata": {},
   "source": [
    "## Gaps Dataset Builder Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04bdd18-ed54-4464-9ec9-a341a95200a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_with_gaps(n=1000, T_max=1000, dt_min=0.05, dt_max=0.20, seed=42):  \n",
    "    \"\"\"\n",
    "    Build my dataset with gaps for training inside an artificial neural network.\n",
    "\n",
    "    Args:\n",
    "        n (int): Number of sequences (samples) to generate.\n",
    "        T_max (int): Max length of the sequence after padding.\n",
    "        dt_min (float): Minimum per-frame time step in seconds. \n",
    "        dt_max (float): Maximum per-frame time step in seconds. \n",
    "        seed (int): Seed for numpy's generator.  \n",
    "\n",
    "    Returns:\n",
    "        X_frames (np.ndarray): my frames tensor, shape (n, T_max, 28, 28, 1).\n",
    "        X_dts (np.ndarray): my dts tensor, shape (n, T_max, 1).\n",
    "        y (np.ndarray): my labels tensor, shape (n,); 1 label per sequence with a integer from 0 to 47.  \n",
    "        gaps_length (np.ndarray): my gaps durations tensor, shape (n, 3), the actual gaps value (gap_a, gap_b, gap_c).\n",
    "        \n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed) \n",
    "    X_frames, X_dts, y, gaps_length = [], [], [], []\n",
    "    for _ in range(n):\n",
    "        gap_a = rng.uniform(1.0, 5.0)\n",
    "        gap_b = rng.uniform(1.0, 3.0)\n",
    "        gap_c = rng.uniform(1.0, 7.0)\n",
    "        label = label_from_gap(gap_a, gap_b, gap_c)\n",
    "\n",
    "        events = [\n",
    "            (IMG_S, 2.0),\n",
    "            (IMG__, gap_a),\n",
    "            (IMG_C, 3.0),\n",
    "            (IMG__, gap_b),\n",
    "            (IMG_S, 2.0),\n",
    "            (IMG__, gap_c),\n",
    "            (IMG_S, 1.0),\n",
    "        ]\n",
    "        \n",
    "        frames, dts = expand_events(events, dt_min=dt_min, dt_max=dt_max, rng=rng)\n",
    "        \n",
    "        if frames.shape[0] > T_max:\n",
    "            raise ValueError(\"Increase T_max or dt_min to reduces the number of timesteps.\")\n",
    "            \n",
    "        F, D = pad_sequence(frames, dts, T_max)\n",
    "        \n",
    "        X_frames.append(F); X_dts.append(D); y.append(label); gaps_length.append((gap_a,gap_b,gap_c))  \n",
    "        \n",
    "    return np.array(X_frames), np.array(X_dts), np.array(y, np.int32), np.array(gaps_length) #Keras like int32 labels for classification\n",
    "\n",
    "\n",
    "#check the final inputs and outputs shape \n",
    "X_frames, X_dts, y, gaps_length = make_dataset_with_gaps(1000)\n",
    "print(X_frames.shape, X_dts.shape, y.shape)\n",
    "# (1000, T_max, 28,28,1), (1000, T_max, 1), (1000,)\n",
    "\n",
    "\n",
    "def rebuild_from_gaps(gaps, T_max, dt_min, dt_max, seed=42):\n",
    "    \"\"\"\n",
    "    After using make_dataset_with_gaps, it recreate my whole sequence(same gaps, same label), but with different dts;\n",
    "    allowing my model to test it's ability to take into account the real time of my gaps and pictures and not associating the specific dts to the specific frame/label.\n",
    "\n",
    "    Args:\n",
    "        gaps (np.ndarray): shape (n, 3); my gaps from make_dataset_with_gaps. \n",
    "        T_max (int): Max length of the sequence.\n",
    "        dt_min (float): Minimum per-frame time step in seconds; choose a different one from the one used to build the dataset.\n",
    "        dt_max (float): Maximum per-frame time step in seconds; choose a different one from the one used to build the dataset.\n",
    "        seed (int): Seed for numpy's generator.\n",
    "        \n",
    "    Returns:\n",
    "        X_frames (np.ndarray): my frames tensor, shape (n, T_max, 28, 28, 1).\n",
    "        X_dts (np.ndarray): my dts tensor, shape (n, T_max, 1).\n",
    "        y (np.ndarray): my labels tensor, shape (n,).\n",
    "        \n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X_frames, X_dts, y = [], [], []\n",
    "    for (gap_a, gap_b, gap_c) in gaps:\n",
    "        label = label_from_gap(gap_a, gap_b, gap_c)   \n",
    "        events = [(IMG_S,2.0),(IMG__,gap_a),(IMG_C,3.0),(IMG__,gap_b),(IMG_S,2.0),(IMG__,gap_c),(IMG_S,1.0)]\n",
    "        frames, dts = expand_events(events, dt_min=dt_min, dt_max=dt_max, rng=rng)\n",
    "\n",
    "        if frames.shape[0] > T_max:\n",
    "            raise ValueError(f\"Sequence len {frames.shape[0]} exceeds T_max={T_max}.\")\n",
    "       \n",
    "        F, D = pad_sequence(frames, dts, T_max)\n",
    "        X_frames.append(F); X_dts.append(D); y.append(label)\n",
    "    return np.array(X_frames), np.array(X_dts), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3552b-234b-4851-94b3-7b7663219816",
   "metadata": {},
   "source": [
    "## Training and Validation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5715220-ce39-4e69-b2ca-27f5e8515a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500 #choose quantity of sequence generated\n",
    "\n",
    "\n",
    "X_frames, X_dts, y, gaps_length = make_dataset_with_gaps(n=n, T_max=1000, dt_min=0.05, dt_max=0.20, seed=42)  #Can select parameters here \n",
    "print(X_frames.shape, X_dts.shape, y.shape, gaps_length.shape)\n",
    "\n",
    "# Split (keep gaps aligned too)\n",
    "X_frames_train, X_frames_tmp, X_dts_train, X_dts_tmp, y_train, y_tmp, gaps_train, gaps_tmp = train_test_split(\n",
    "    X_frames, X_dts, y, gaps_length, test_size=0.3, random_state=42 #keep 70% for training\n",
    ")\n",
    "X_frames_val, X_frames_test, X_dts_val, X_dts_test, y_val, y_test, gaps_val, gaps_test = train_test_split(\n",
    "    X_frames_tmp, X_dts_tmp, y_tmp, gaps_tmp, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac57c34-fcd1-49e7-a0a7-a5de585dee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 64\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def make_model_dataset(X_frames, X_dts, y, shuffle, seed=None):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((X_frames, X_dts), y))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(X_frames), seed=seed, reshuffle_each_iteration=True)        \n",
    "    return dataset.batch(BATCH).prefetch(AUTOTUNE)                          \n",
    "\n",
    "train_ds = make_model_dataset(X_frames_train, X_dts_train, y_train, shuffle=True,  seed=42)\n",
    "val_ds   = make_model_dataset(X_frames_val,   X_dts_val,   y_val,   shuffle=False)\n",
    "test_ds  = make_model_dataset(X_frames_test,  X_dts_test,  y_test,  shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ec058-7cfb-4399-8fa8-6ccaf49eb5d6",
   "metadata": {},
   "source": [
    "# LMU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e8b44-b163-4277-967c-6ddb31c38572",
   "metadata": {},
   "source": [
    "## LMU Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e9968-ab3e-4bc4-a666-670e964b2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read LMU documentation at Nengo.ai for more information on the implementation of the LMU \n",
    "\n",
    "class LMUVarDtCell(K.layers.Layer):  # behaves like an RNN cell\n",
    "    def __init__(self, input_size, order=32, theta=30.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_size = input_size #input size after passing through the CNN *verify \n",
    "        self.order = order           #q ; the Legendre memory *basis* order. Higher = richer/longer history \n",
    "        self.theta = float(theta)    #Memory window in seconds \n",
    "        # learnable projection E: R^{input_size} -> R^{1}\n",
    "        self.proj = K.layers.Dense(1, use_bias=False) #CNN feature vector is squashed in the number of drive signal corresponding to 1 here\n",
    "        self.state_size = self.order #LMU memory as a flat vector for keras layers instead of (batch, order, 1) for LMU math \n",
    "\n",
    "    def build(self, input_shape): #Override default Keras build () Variables tied to the layer\n",
    "        # Precompute continuous-time A_c, B_c (Legendre Delay Network (LDN))\n",
    "        q = self.order\n",
    "        i = tf.reshape(tf.range(q, dtype=tf.float32), (-1, 1))  # (q,1)\n",
    "        j = tf.reshape(tf.range(q, dtype=tf.float32), (1, -1))  # (1,q)\n",
    "        R = (2.0 * i + 1.0) / self.theta                         # (q,1)\n",
    "        \n",
    "        A = tf.where(i < j, -1.0, tf.pow(-1.0, i - j + 1.0)) * R  # (q,q)\n",
    "        B = tf.pow(-1.0, i) * R                                   # (q,1)\n",
    "        \n",
    "        self.A_c = tf.Variable(A, trainable=False, name=\"A_c\")\n",
    "        self.B_c = tf.Variable(B, trainable=False, name=\"B_c\")\n",
    "\n",
    "    def call(self, inputs, states): #Keras call once per timestep.\n",
    "        \"\"\"\n",
    "        inputs: [x_t, dt_t] where\n",
    "            x_t: (batch, input_size) #CNN features at time t\n",
    "            dt_t: (batch, 1)         #real seconds for this step  \n",
    "        state:  (batch, q)  #previous LMU memory, flattened \n",
    "        \"\"\"\n",
    "        x_dt = inputs\n",
    "        x_t = x_dt[:, :self.input_size] # (batch_size, input_size)\n",
    "        dt_t = x_dt[:, self.input_size:] # (batch_size, 1)\n",
    "        batch_size = tf.shape(x_t)[0] #batch size \n",
    "        q = self.order\n",
    "        \n",
    "        # Build augmented matrix\n",
    "        # M = [[A_c, B_c],\n",
    "        #      [ 0 ,  0 ]]\n",
    "        # Under ZOH\n",
    "        # expm(M * dt) = [[A_d(dt), B_d(dt)],\n",
    "        #                 [   0    ,   I    ]]\n",
    "        top = tf.concat([self.A_c, self.B_c], axis=1)  # (q, q+1)\n",
    "        bottom = tf.zeros((1, self.order + 1), tf.float32)  # (1, q+1)\n",
    "        M = tf.concat([top,bottom], axis=0)  # shape (q+1, q+1), but last row zeros ensures block exp works for [Ad Bd; 0 0]\n",
    "\n",
    "        # Drive signal (project CNN features -> u_t)\n",
    "        u_t = self.proj(x_t)  # (batch_size, 1)  \n",
    "\n",
    "        # # reshape state to (batch, q, 1) for consistent matmul\n",
    "        m = tf.reshape(states[0], (batch_size, q, 1))  # (batch_size,q,1)\n",
    "\n",
    "        # Continuous-time LMU -> per-step discrete update with the Zero-order hold (ZOH) discretization \n",
    "        # Compute exp(M * dt) per batch item (variable dt)\n",
    "        def one_timestep(args):\n",
    "            m_b, u_b, dt_b = args\n",
    "            \n",
    "\n",
    "\n",
    "            #compute the matrix exponential at that dt\n",
    "            # Md = [[A_d, B_d],\n",
    "            #       [  0 ,  I ]]\n",
    "            Md = tf.linalg.expm(M * dt_b)          # (q+1, q+1)\n",
    "            \n",
    "            #Get my A and B \n",
    "            Ad = Md[:q, :q]                        # (q,q)\n",
    "            Bd = Md[:q, q:q+1]                     # (q,1)\n",
    "\n",
    "            m_updated = tf.matmul(Ad, m_b) + tf.matmul(Bd, u_b[:, None])  # (q,1)  #m_{t+Δt} = A_d * m_t + B_d * u_t  \n",
    "            \n",
    "            return tf.reshape(m_updated, (q, 1))\n",
    "\n",
    "        #run it for each batch item \n",
    "        m_next = tf.map_fn( one_timestep,\n",
    "                            (m, u_t, tf.reshape(dt_t, (-1, 1))),\n",
    "                            fn_output_signature=tf.TensorSpec(shape=(q, 1), dtype=tf.float32)\n",
    "                           )\n",
    "        m_next = tf.reshape(m_next, (batch_size, q)) #same as self.state_size; flatten \n",
    "        return m_next, [m_next]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e285ee8-7782-4ac3-af47-8dea39d14028",
   "metadata": {},
   "source": [
    "## LMU for Classification (bins) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73ea7b-393c-4478-8678-e1388579d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD LMU - CLASSIFICATION\n",
    "def build_continuous_lmu_cls(T, theta=30.0, order=32, cnn_out=32, n_classes=48):\n",
    "    frames = K.Input((T, 28, 28, 1))\n",
    "    dts    = K.Input((T, 1))\n",
    "\n",
    "    feat = K.layers.TimeDistributed(\n",
    "        K.Sequential([\n",
    "            K.layers.Conv2D(8, 3, padding=\"same\", activation=\"relu\"),\n",
    "            K.layers.MaxPool2D(2),\n",
    "            K.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "            K.layers.Flatten(),\n",
    "            K.layers.Dense(cnn_out),\n",
    "        ])\n",
    "    )(frames)   # (B,T,cnn_out)\n",
    "\n",
    "    mask  = K.layers.Lambda(lambda x: tf.squeeze(x, -1) > 0.0)(dts)  # (B,T) booleans\n",
    "    xcat  = K.layers.Concatenate(axis=-1)([feat, dts])               # (B,T,cnn_out+1)\n",
    "\n",
    "    cell   = LMUVarDtCell(input_size=cnn_out, order=order, theta=theta)\n",
    "    m_last = K.layers.RNN(cell, return_sequences=False)(xcat, mask=mask)  # (B,q)\n",
    "\n",
    "    logits = K.layers.Dense(n_classes, activation=None)(m_last)  # logits for 0..n_classes-1\n",
    "    model  = K.Model([frames, dts], logits)\n",
    "    model.compile(\n",
    "        optimizer=K.optimizers.Adam(2e-3, clipnorm=1.0), #learning rate \n",
    "        loss=K.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[K.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be6729-5870-44b3-a41e-7e39edb0aa6a",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e4092-506a-4f07-b901-06d7e98f61e2",
   "metadata": {},
   "source": [
    "## LSTM for Classification (bins) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cce1d0-8470-4aaf-af65-831d282e8ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_with_dt_cls(T, cnn_out=32, lstm_units=32, use_cumtime=True):\n",
    "    frames = K.Input((T, 28, 28, 1), name=\"frames\")\n",
    "    dts    = K.Input((T, 1),          name=\"dts\")\n",
    "\n",
    "    feat = K.layers.TimeDistributed(\n",
    "        K.Sequential([\n",
    "            K.layers.Conv2D(8, 3, padding=\"same\", activation=\"relu\"),\n",
    "            K.layers.MaxPool2D(2),\n",
    "            K.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "            K.layers.Flatten(),\n",
    "            K.layers.Dense(cnn_out),\n",
    "        ], name=\"cnn\")\n",
    "    )(frames)\n",
    "\n",
    "    # Mask from padded dts==0\n",
    "    mask = K.layers.Lambda(lambda x: tf.squeeze(x, -1) > 0.0, name=\"mask_from_dt\")(dts)\n",
    "\n",
    "    feats = [feat]                  # CNN features (T, cnn_out)\n",
    "    feats.append(dts)               # add per-step dt as a feature (T, 1)\n",
    "\n",
    "    if use_cumtime:\n",
    "        # cumulative time; optionally normalize to [0,1] per sequence\n",
    "        cum_t = K.layers.Lambda(lambda x: tf.cumsum(x, axis=1), name=\"cumtime\")(dts)\n",
    "        # norm_cum_t = cum_t / (K.backend.maximum(K.backend.epsilon(), K.backend.sum(dts, axis=1, keepdims=True)))\n",
    "        feats.append(cum_t)         # or feats.append(norm_cum_t)\n",
    "\n",
    "    xseq = K.layers.Concatenate(axis=-1, name=\"concat_feats\")(feats)  # (T, cnn_out + 1 [+ 1])\n",
    "\n",
    "    h_last = K.layers.LSTM(lstm_units, return_sequences=False, name=\"lstm\")(xseq, mask=mask)\n",
    "    out = K.layers.Dense(48, activation=None, name=\"logits\")(h_last)\n",
    "\n",
    "    model = K.Model([frames, dts], out, name=\"lstm_with_dt_cls\")\n",
    "    model.compile(\n",
    "        optimizer=K.optimizers.Adam(2e-3, clipnorm=1.0), #learning rate \n",
    "        loss=K.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[K.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6fe366-09de-4170-bfb6-741e5a876a78",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51374c49-ea19-42d0-9312-74e1b427f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_max = X_frames.shape[1] \n",
    "lmu   = build_continuous_lmu_cls(T=T_max, theta=30.0, order=32, cnn_out=32) \n",
    "lstm  = build_lstm_with_dt_cls   (T=T_max,               cnn_out=32, lstm_units=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4818bdb-1484-465a-984b-3b36d2eb107e",
   "metadata": {},
   "source": [
    "## LMU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15754e6c-4e87-43a5-b0a2-9d7eebd4f964",
   "metadata": {},
   "source": [
    "### LMU Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cf9a02-8f50-4cb4-b5f8-df7cb83104f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = f\"n{n}_dt05-20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bfa20b-9b7c-47e4-a972-c426992bbd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LMU\n",
    "cb_es_lmu = [\n",
    "    K.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True),\n",
    "    K.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5), #multiply learning rate by 0.5 if doesn't improve, minimum learning rate 1e-5\n",
    "] #monitor \"val_mae\" or \"val_loss\"\n",
    "\n",
    "ckpt_lmu = K.callbacks.ModelCheckpoint(\n",
    "    f\"best_lmu_cls_{run_id}.weights.h5\",\n",
    "    monitor=\"val_loss\", mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,   \n",
    ")\n",
    "\n",
    "csv_logger_lmu = K.callbacks.CSVLogger(f\"lmu_train_log_{run_id}.csv\", append=False)\n",
    "callbacks_lmu = cb_es_lmu + [ckpt_lmu, csv_logger_lmu]\n",
    "hist_lmu  = lmu.fit (train_ds, validation_data=val_ds, epochs=100, callbacks=callbacks_lmu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6e561-3a8b-4a60-b0cc-00cc8902ae71",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440fcd9-5227-4a58-8208-153e9e44a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, reload \n",
    "lmu = build_continuous_lmu_cls(T=T_max, theta=30.0, order=32, cnn_out=32, n_classes=48)\n",
    "_ = lmu([tf.zeros((1, T_max, 28, 28, 1)), tf.zeros((1, T_max, 1))])  # builds variables\n",
    "lmu.load_weights(f\"best_lmu_cls_{run_id}.weights.h5\")\n",
    "\n",
    "df_lmu = pd.read_csv(f\"lmu_train_log_{run_id}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d391d4-33cb-4e95-93ca-77bd275817ea",
   "metadata": {},
   "source": [
    "### LMU Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cca8b0-a427-4a40-8ff8-8221b5629da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LMU\n",
    "val_lmu  = lmu.evaluate(val_ds,  verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fdfc8c-96db-488b-a1a0-b0ba71581517",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmu.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ec144-9434-4d5c-8daf-db8105e94347",
   "metadata": {},
   "source": [
    "### LMU Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d51eeb-462d-409d-aeb8-eef3528b4e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Validation data\n",
    "print(\"run_id is: \", run_id) \n",
    "print(f\"LMU val_loss and val_acc for n={n}\")\n",
    "print(val_lmu) #val_loss, val_acc\n",
    "\n",
    "\n",
    "\n",
    "#Training on the data epochs \n",
    "plt.figure()\n",
    "plt.plot(df_lmu[\"epoch\"], df_lmu[\"loss\"], label=\"train loss\")\n",
    "plt.plot(df_lmu[\"epoch\"], df_lmu[\"val_loss\"], label=\"val loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.legend(); plt.tight_layout()\n",
    "plt.title(f\"LMU Training vs Validation Loss (n={n})\")\n",
    "\n",
    "#save the plot \n",
    "plt.savefig(f\"loss_curve_LMU_{run_id}.png\", dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c993e-77ae-4b86-819c-6086eefa7a6d",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a486e-4e88-46d7-985d-799793ac3870",
   "metadata": {},
   "source": [
    "### LSTM Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773184bf-8a44-4c89-8f1d-33b2dbaed097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "cb_es_lstm = [\n",
    "    K.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
    "    K.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-5), #multiply learning rate by 0.5 if doesn't improve, minimum learning rate 1e-5\n",
    "] #monitor \"val_mae\" or \"val_loss\"\n",
    "\n",
    "ckpt_lstm = K.callbacks.ModelCheckpoint(\n",
    "    f\"best_lstm_cls_{run_id}.weights.h5\",\n",
    "    monitor=\"val_loss\", mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "csv_logger_lstm = K.callbacks.CSVLogger(f\"lstm_train_log_{run_id}.csv\", append=False)\n",
    "callbacks_lstm = cb_es_lstm + [ckpt_lstm, csv_logger_lstm]\n",
    "hist_lstm = lstm.fit(train_ds, validation_data=val_ds, epochs=1000, callbacks=callbacks_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb0846-5ecf-40fb-815a-44885bc640a9",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14684704-9bb8-4614-b2e8-b653ab7557e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload + logs\n",
    "lstm = build_lstm_with_dt_cls(T=T_max, cnn_out=32, lstm_units=32, use_cumtime=True)\n",
    "lstm.load_weights(f\"best_lstm_cls_{run_id}.weights.h5\")\n",
    "df_lstm = pd.read_csv(f\"lstm_train_log_{run_id}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fdb906-3848-4620-8c3a-7b81206e5503",
   "metadata": {},
   "source": [
    "### LSTM Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54825b-ffaa-4559-8c60-35713031f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "val_lstm = lstm.evaluate(val_ds, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d69ae1-97de-43e2-8e3d-cfa04dfbb054",
   "metadata": {},
   "source": [
    "### LSTM Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a59f7-3949-4e33-be41-017c2eda4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d1884-5253-4f73-8a58-9ef4ee3d409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation data\n",
    "print(\"run_id is: \", run_id) \n",
    "print(f\"LSTM val_loss and val_acc for n={n}\")\n",
    "print(val_lstm)\n",
    "\n",
    "\n",
    "#Training on the data epochs \n",
    "plt.figure()\n",
    "plt.plot(df_lstm[\"epoch\"], df_lstm[\"loss\"], label=\"train loss\")\n",
    "plt.plot(df_lstm[\"epoch\"], df_lstm[\"val_loss\"], label=\"val loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.legend(); plt.tight_layout()\n",
    "plt.title(f\"LSTM Training vs Validation Loss (n={n})\")\n",
    "\n",
    "plt.savefig(f\"loss_curve_LSTM_{run_id}.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94048b-e724-4c2a-b759-570d94c3b8e1",
   "metadata": {},
   "source": [
    "## LMU V.S LSTM on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387c414-54a0-4d4f-808f-bfed9d4033b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"run_id is: \", run_id) \n",
    "print(\"----------------------------------------\")\n",
    "print(f\"LMU val_loss and val_acc for n={n}\")\n",
    "print(val_lmu) #val_loss, val_acc\n",
    "print(\"----------------------------------------\")\n",
    "print(f\"LSTM val_loss and val_acc for n={n}\")\n",
    "print(val_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbef9b-e938-4446-bcbf-f87d1e369608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best-epoch indices (by val_loss)\n",
    "i_best_lmu  = int(df_lmu[\"val_loss\"].idxmin())\n",
    "i_best_lstm = int(df_lstm[\"val_loss\"].idxmin())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n",
    "\n",
    "# --- Left: val_loss\n",
    "axes[0].plot(df_lmu[\"epoch\"],  df_lmu[\"val_loss\"],  label=\"LMU\")\n",
    "axes[0].plot(df_lstm[\"epoch\"], df_lstm[\"val_loss\"], label=\"LSTM\")\n",
    "axes[0].scatter(df_lmu.loc[i_best_lmu,  \"epoch\"], df_lmu.loc[i_best_lmu,  \"val_loss\"],  marker=\"o\")\n",
    "axes[0].scatter(df_lstm.loc[i_best_lstm, \"epoch\"], df_lstm.loc[i_best_lstm, \"val_loss\"], marker=\"o\")\n",
    "axes[0].set_title(\"Validation Loss\")\n",
    "axes[0].set_xlabel(\"epoch\"); axes[0].set_ylabel(\"loss\"); axes[0].legend()\n",
    "\n",
    "# --- Right: val_acc\n",
    "axes[1].plot(df_lmu[\"epoch\"],  df_lmu[\"val_acc\"],  label=\"LMU\")\n",
    "axes[1].plot(df_lstm[\"epoch\"], df_lstm[\"val_acc\"], label=\"LSTM\")\n",
    "axes[1].scatter(df_lmu.loc[i_best_lmu,  \"epoch\"], df_lmu.loc[i_best_lmu,  \"val_acc\"],  marker=\"o\")\n",
    "axes[1].scatter(df_lstm.loc[i_best_lstm, \"epoch\"], df_lstm.loc[i_best_lstm, \"val_acc\"], marker=\"o\")\n",
    "axes[1].set_title(\"Validation Accuracy\")\n",
    "axes[1].set_xlabel(\"epoch\"); axes[1].set_ylabel(\"accuracy\"); axes[1].legend()\n",
    "\n",
    "fig.suptitle(f\"LMU vs LSTM (n={n})\", y=1.02)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"compare_lmu_lstm_{run_id}.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f817f-54d5-4db4-8e11-413b5afb666e",
   "metadata": {},
   "source": [
    "# Evaluate on Different Gaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927d649-8f49-4ac2-9b34-7d4844c38c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild SLOW test with the exact same gaps\n",
    "X_frames_slow, X_dts_slow, y_slow = rebuild_from_gaps(gaps_test, T_max=T_max, dt_min=0.10, dt_max=0.40, seed=42)  #or gaps_length[:300]\n",
    "slow_ds = tf.data.Dataset.from_tensor_slices(((X_frames_slow, X_dts_slow), y_slow)).batch(64)\n",
    "\n",
    "# Evaluate both models on the rebuilt data\n",
    "loss_lmu, acc_lmu   = lmu.evaluate(slow_ds, verbose=0)\n",
    "loss_lstm, acc_lstm = lstm.evaluate(slow_ds, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b474bcd-a383-4463-96da-cf4508bdd308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print results \n",
    "\n",
    "print(\"Size of dataset\", n)\n",
    "print(\"Slow rebuild: dt_min = 0.10, dt_max = 0.40\")\n",
    "print(f\"LMU  — loss: {loss_lmu:.4f}, acc: {acc_lmu:.4f}\")\n",
    "print(f\"LSTM — loss: {loss_lstm:.4f}, acc: {acc_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c0fcd-e1d0-44f4-9809-5b3bac2b3a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild FAST test with the exact same gaps\n",
    "X_frames_fast, X_dts_fast, y_fast = rebuild_from_gaps(gaps_test, T_max=T_max, dt_min=0.025, dt_max=0.10, seed=42)  #or gaps_length[:300]\n",
    "fast_ds = tf.data.Dataset.from_tensor_slices(((X_frames_fast, X_dts_fast), y_fast)).batch(64)\n",
    "\n",
    "# Evaluate both models on the rebuilt data\n",
    "loss_lmu, acc_lmu   = lmu.evaluate(fast_ds, verbose=0)\n",
    "loss_lstm, acc_lstm = lstm.evaluate(fast_ds, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9eec69-600e-4de4-8ee4-730042ebe1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print results \n",
    "\n",
    "print(\"Size of dataset\", n)\n",
    "print(\"Fast rebuild: dt_min = 0.025, dt_max = 0.10\")\n",
    "print(f\"LMU  — loss: {loss_lmu:.4f}, acc: {acc_lmu:.4f}\")\n",
    "print(f\"LSTM — loss: {loss_lstm:.4f}, acc: {acc_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2cca9-7e94-4e41-8eb8-3409760dc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug in your numbers\n",
    "val_lmu_acc   = 0.5866666436195374\n",
    "slow_lmu_acc  = 0.5733\n",
    "fast_lmu_acc  = 0.5733\n",
    "\n",
    "val_lstm_acc  = 0.3733333349227905\n",
    "slow_lstm_acc = 0.0800\n",
    "fast_lstm_acc = 0.2000\n",
    "\n",
    "# done plugging numbers\n",
    "labels = [\"VAL (0.05–0.20)\", \"SLOW (0.10–0.40)\", \"FAST (0.025–0.10)\"]\n",
    "lmu    = [val_lmu_acc,  slow_lmu_acc,  fast_lmu_acc]\n",
    "lstm   = [val_lstm_acc, slow_lstm_acc, fast_lstm_acc]\n",
    "\n",
    "x = np.arange(len(labels)); w = 0.35\n",
    "fig, ax = plt.subplots(figsize=(7.5,4))\n",
    "ax.bar(x - w/2, lmu,  width=w, label=\"LMU\")\n",
    "ax.bar(x + w/2, lstm, width=w, label=\"LSTM\")\n",
    "ax.set_xticks(x); ax.set_xticklabels(labels, rotation=0)\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(f\"Resampling Robustness (n={n})\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"robustness_compare_{run_id}.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# print drops\n",
    "def drop(a,b): return 100*(a-b)/max(a,1e-8)\n",
    "print(f\"LMU  drop: VAL→SLOW {drop(val_lmu_acc, slow_lmu_acc):.1f}%, VAL→FAST {drop(val_lmu_acc, fast_lmu_acc):.1f}%\")\n",
    "print(f\"LSTM drop: VAL→SLOW {drop(val_lstm_acc, slow_lstm_acc):.1f}%, VAL→FAST {drop(val_lstm_acc, fast_lstm_acc):.1f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
